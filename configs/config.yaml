# configs/config.yaml
model: "meta-llama/llama-4-scout-17b-16e-instruct"
temperature: 0.7
max_tokens: 1024
base_url: "https://api.groq.com/openai/v1"
timeout: 30
retry_count: 3
